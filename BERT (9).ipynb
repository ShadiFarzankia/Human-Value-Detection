{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BERT\n",
        "\n",
        "### Introduction\n",
        "In this notebook, our objective is to train an BERT model for a challenging multilabel classification task. This task involves categorizing textual arguments into one or more of 20 distinct categories, each representing a fundamental human value.\n",
        "\n",
        "The categories are as follows:\n",
        "- Self-direction: thought\n",
        "- Self-direction: action\n",
        "- Stimulation\n",
        "- Hedonism\n",
        "- Achievement\n",
        "- Power: dominance\n",
        "- Power: resources\n",
        "- Face\n",
        "- Security: personal\n",
        "- Security: societal\n",
        "- Tradition\n",
        "- Conformity: rules\n",
        "- Conformity: interpersonal\n",
        "- Humility\n",
        "- Benevolence: caring\n",
        "- Benevolence: dependability\n",
        "- Universalism: concern\n",
        "- Universalism: nature\n",
        "- Universalism: tolerance\n",
        "- Universalism: objectivity\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yoQ0lKhx7JnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Flow of the notebook\n",
        "\n",
        "\n",
        "The notebook will be structured into distinct sections to offer a well-organized guide through the implemented process. These sections will include:\n",
        "\n",
        "1. Installing the required libraries\n",
        "2. Importing the libraries\n",
        "3. Loading the datasets\n",
        "3. Defining and Fine-Tuning the Model\n",
        "  - BERT Base\n",
        "  - BERT Large\n",
        "4. Evaluation"
      ],
      "metadata": {
        "id": "XWQbJ1P_7TCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing the Required Libraries\n",
        "\n",
        "We have to install the libraries below because it is not be pre-installed in the runtime environment provided by Google Colab:\n",
        "- transformers\n",
        "- SentencePiece\n",
        "- wandb\n",
        "- simpletransformers"
      ],
      "metadata": {
        "id": "aEnEdPCo74Zj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gNHkPmU70ez"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SentencePiece"
      ],
      "metadata": {
        "id": "nGOgwwjd8Hrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb --upgrade"
      ],
      "metadata": {
        "id": "NpKM4_MPIMFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade wandb simpletransformers"
      ],
      "metadata": {
        "id": "G8H9M2oTcKyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install simpletransformers"
      ],
      "metadata": {
        "id": "_edMZrO28JX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the Libraries"
      ],
      "metadata": {
        "id": "o2ncKBbL8MMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "import logging\n",
        "import wandb\n",
        "\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from simpletransformers.classification import MultiLabelClassificationModel, ClassificationArgs\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, classification_report"
      ],
      "metadata": {
        "id": "7Fr2hUjM8P-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Data\n",
        "We utilize data sourced from [Zenodo](https://zenodo.org/record/7550385#.Y8wMquzMK3I), specifically from the [Human Value Detection 2023 competition](https://touche.webis.de/semeval23/touche23-web/index.html). Our focus is on the following datasets: arguments-training.tsv, arguments-validation.tsv, arguments-test.tsv, labels-training.tsv, labels-validation.tsv, and labels-test.tsv.\n"
      ],
      "metadata": {
        "id": "7KL5rVH18Rcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the label titles in our datasets\n",
        "label_cols = ['Self-direction: thought', 'Self-direction: action', 'Stimulation',\n",
        "       'Hedonism', 'Achievement', 'Power: dominance', 'Power: resources',\n",
        "       'Face', 'Security: personal', 'Security: societal', 'Tradition',\n",
        "       'Conformity: rules', 'Conformity: interpersonal', 'Humility',\n",
        "       'Benevolence: caring', 'Benevolence: dependability',\n",
        "       'Universalism: concern', 'Universalism: nature',\n",
        "       'Universalism: tolerance', 'Universalism: objectivity']"
      ],
      "metadata": {
        "id": "Sf1yw97Xyo6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the data\n",
        "train_args = pd.read_csv(\"arguments-training.tsv\",delimiter='\\t')\n",
        "train_labels = pd.read_csv(\"labels-training.tsv\",delimiter='\\t')\n",
        "\n",
        "val_labels = pd.read_csv(\"labels-validation.tsv\",delimiter='\\t')\n",
        "val_args = pd.read_csv(\"arguments-validation.tsv\",delimiter='\\t')\n",
        "\n",
        "test_labels = pd.read_csv(\"labels-test.tsv\",delimiter='\\t')\n",
        "test_args = pd.read_csv(\"arguments-test.tsv\",delimiter='\\t')"
      ],
      "metadata": {
        "id": "WnKxwEPs8W-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The input data for simple transformers' models need to have a 'text' column containing the context we need to apply multiclassification and the list of labels for each element in the context."
      ],
      "metadata": {
        "id": "6MND0ySO8ION"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the 'text' column\n",
        "train_args['text'] = train_args['Conclusion'] + \" \" + train_args['Stance'] + \" \" + train_args['Premise']\n",
        "train_args.drop(labels=['Conclusion', 'Stance', 'Premise'], axis=1, inplace=True)\n",
        "\n",
        "val_args['text'] = val_args['Conclusion'] + \" \" + val_args['Stance'] + \" \" + val_args['Premise']\n",
        "val_args.drop(labels=['Conclusion', 'Stance', 'Premise'], axis=1, inplace=True)\n",
        "\n",
        "test_args['text'] = test_args['Conclusion'] + \" \" + test_args['Stance'] + \" \" + test_args['Premise']\n",
        "test_args.drop(labels=['Conclusion', 'Stance', 'Premise'], axis=1, inplace=True)\n",
        "\n",
        "print(val_labels)"
      ],
      "metadata": {
        "id": "FI-dEUz58Y4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6d54964-9616-4ece-c093-f2a5a5f9e9e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Argument ID  Self-direction: thought  Self-direction: action  \\\n",
            "0         A01001                        0                       0   \n",
            "1         A01012                        0                       0   \n",
            "2         A02001                        0                       0   \n",
            "3         A02002                        0                       1   \n",
            "4         A02009                        0                       0   \n",
            "...          ...                      ...                     ...   \n",
            "1891      E08014                        1                       0   \n",
            "1892      E08021                        1                       0   \n",
            "1893      E08022                        0                       1   \n",
            "1894      E08024                        0                       1   \n",
            "1895      E08025                        0                       1   \n",
            "\n",
            "      Stimulation  Hedonism  Achievement  Power: dominance  Power: resources  \\\n",
            "0               0         0            0                 0                 0   \n",
            "1               0         0            0                 0                 0   \n",
            "2               0         0            0                 0                 0   \n",
            "3               0         0            0                 0                 0   \n",
            "4               0         0            0                 0                 0   \n",
            "...           ...       ...          ...               ...               ...   \n",
            "1891            0         0            1                 0                 0   \n",
            "1892            0         0            0                 0                 0   \n",
            "1893            0         0            0                 0                 0   \n",
            "1894            0         0            0                 1                 0   \n",
            "1895            0         0            0                 0                 0   \n",
            "\n",
            "      Face  Security: personal  ...  Tradition  Conformity: rules  \\\n",
            "0        0                   0  ...          0                  0   \n",
            "1        0                   0  ...          0                  0   \n",
            "2        0                   1  ...          0                  0   \n",
            "3        0                   0  ...          0                  0   \n",
            "4        0                   0  ...          0                  1   \n",
            "...    ...                 ...  ...        ...                ...   \n",
            "1891     0                   1  ...          0                  1   \n",
            "1892     0                   0  ...          0                  1   \n",
            "1893     0                   0  ...          0                  1   \n",
            "1894     0                   1  ...          0                  0   \n",
            "1895     0                   0  ...          0                  0   \n",
            "\n",
            "      Conformity: interpersonal  Humility  Benevolence: caring  \\\n",
            "0                             0         0                    0   \n",
            "1                             0         0                    0   \n",
            "2                             0         0                    0   \n",
            "3                             0         0                    0   \n",
            "4                             0         0                    0   \n",
            "...                         ...       ...                  ...   \n",
            "1891                          0         0                    0   \n",
            "1892                          0         0                    0   \n",
            "1893                          0         0                    0   \n",
            "1894                          0         0                    0   \n",
            "1895                          0         0                    0   \n",
            "\n",
            "      Benevolence: dependability  Universalism: concern  Universalism: nature  \\\n",
            "0                              0                      0                     0   \n",
            "1                              0                      1                     0   \n",
            "2                              0                      1                     0   \n",
            "3                              0                      0                     0   \n",
            "4                              0                      1                     0   \n",
            "...                          ...                    ...                   ...   \n",
            "1891                           0                      1                     0   \n",
            "1892                           1                      1                     0   \n",
            "1893                           1                      1                     0   \n",
            "1894                           0                      1                     0   \n",
            "1895                           0                      1                     0   \n",
            "\n",
            "      Universalism: tolerance  Universalism: objectivity  \n",
            "0                           0                          0  \n",
            "1                           0                          0  \n",
            "2                           0                          0  \n",
            "3                           0                          0  \n",
            "4                           0                          1  \n",
            "...                       ...                        ...  \n",
            "1891                        0                          1  \n",
            "1892                        0                          1  \n",
            "1893                        0                          1  \n",
            "1894                        0                          1  \n",
            "1895                        0                          0  \n",
            "\n",
            "[1896 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_labels(data):\n",
        "  df = pd.DataFrame(data)\n",
        "\n",
        "  final_list = df.copy()  # Make a copy of the DataFrame\n",
        "  final_list['labels'] = df.iloc[:, 1:].apply(lambda row: tuple(row), axis=1)\n",
        "\n",
        "  return final_list"
      ],
      "metadata": {
        "id": "SBUXQjiE8c1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the 'labels' column\n",
        "train_labels_compressed = prepare_labels(train_labels)\n",
        "val_labels_compressed = prepare_labels(val_labels)\n",
        "test_labels_compressed = prepare_labels(test_labels)\n",
        "\n",
        "print(train_labels_compressed)"
      ],
      "metadata": {
        "id": "eL2AyF638kKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d2f81cb-5b52-4918-cf83-3b9a25ca8f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Argument ID  Self-direction: thought  Self-direction: action  \\\n",
            "0         A01002                        0                       0   \n",
            "1         A01005                        0                       0   \n",
            "2         A01006                        0                       0   \n",
            "3         A01007                        0                       0   \n",
            "4         A01008                        0                       0   \n",
            "...          ...                      ...                     ...   \n",
            "5388      E08016                        0                       0   \n",
            "5389      E08017                        0                       0   \n",
            "5390      E08018                        0                       0   \n",
            "5391      E08019                        0                       0   \n",
            "5392      E08020                        0                       1   \n",
            "\n",
            "      Stimulation  Hedonism  Achievement  Power: dominance  Power: resources  \\\n",
            "0               0         0            0                 0                 0   \n",
            "1               0         0            0                 0                 0   \n",
            "2               0         0            0                 1                 0   \n",
            "3               0         0            0                 0                 0   \n",
            "4               0         0            0                 0                 0   \n",
            "...           ...       ...          ...               ...               ...   \n",
            "5388            0         0            1                 1                 0   \n",
            "5389            0         0            0                 0                 0   \n",
            "5390            0         0            0                 0                 0   \n",
            "5391            0         0            0                 0                 0   \n",
            "5392            0         0            0                 1                 0   \n",
            "\n",
            "      Face  Security: personal  ...  Conformity: rules  \\\n",
            "0        0                   0  ...                  0   \n",
            "1        0                   1  ...                  0   \n",
            "2        0                   0  ...                  0   \n",
            "3        0                   0  ...                  1   \n",
            "4        0                   1  ...                  0   \n",
            "...    ...                 ...  ...                ...   \n",
            "5388     0                   0  ...                  0   \n",
            "5389     0                   1  ...                  1   \n",
            "5390     0                   0  ...                  0   \n",
            "5391     0                   1  ...                  1   \n",
            "5392     0                   0  ...                  0   \n",
            "\n",
            "      Conformity: interpersonal  Humility  Benevolence: caring  \\\n",
            "0                             0         0                    0   \n",
            "1                             0         0                    0   \n",
            "2                             0         0                    0   \n",
            "3                             0         0                    0   \n",
            "4                             0         0                    1   \n",
            "...                         ...       ...                  ...   \n",
            "5388                          0         0                    0   \n",
            "5389                          0         0                    0   \n",
            "5390                          0         0                    0   \n",
            "5391                          0         0                    0   \n",
            "5392                          0         0                    0   \n",
            "\n",
            "      Benevolence: dependability  Universalism: concern  Universalism: nature  \\\n",
            "0                              0                      0                     0   \n",
            "1                              0                      0                     0   \n",
            "2                              0                      0                     0   \n",
            "3                              0                      1                     0   \n",
            "4                              0                      1                     0   \n",
            "...                          ...                    ...                   ...   \n",
            "5388                           1                      0                     0   \n",
            "5389                           1                      1                     0   \n",
            "5390                           1                      0                     1   \n",
            "5391                           1                      1                     0   \n",
            "5392                           1                      0                     0   \n",
            "\n",
            "      Universalism: tolerance  Universalism: objectivity  \\\n",
            "0                           0                          0   \n",
            "1                           0                          0   \n",
            "2                           0                          0   \n",
            "3                           0                          0   \n",
            "4                           0                          0   \n",
            "...                       ...                        ...   \n",
            "5388                        0                          0   \n",
            "5389                        0                          1   \n",
            "5390                        0                          0   \n",
            "5391                        0                          1   \n",
            "5392                        0                          0   \n",
            "\n",
            "                                                 labels  \n",
            "0     (0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
            "1     (0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
            "2     (0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
            "3     (0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, ...  \n",
            "4     (0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...  \n",
            "...                                                 ...  \n",
            "5388  (0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
            "5389  (0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...  \n",
            "5390  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
            "5391  (0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, ...  \n",
            "5392  (0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
            "\n",
            "[5393 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging the content of two files into one dataset\n",
        "merged_train = pd.merge(train_args, train_labels_compressed, on='Argument ID', how='inner')\n",
        "merged_val = pd.merge(val_args, val_labels_compressed, on='Argument ID', how='inner')\n",
        "merged_test = pd.merge(test_args, test_labels_compressed, on='Argument ID', how='inner')\n",
        "\n",
        "print(merged_train)"
      ],
      "metadata": {
        "id": "7Ww6CXCI8sxL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a04d1a08-ad80-490f-aefd-a86666919a2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Argument ID                                               text  \\\n",
            "0         A01002  We should ban human cloning in favor of we sho...   \n",
            "1         A01005  We should ban fast food in favor of fast food ...   \n",
            "2         A01006  We should end the use of economic sanctions ag...   \n",
            "3         A01007  We should abolish capital punishment against c...   \n",
            "4         A01008  We should ban factory farming against factory ...   \n",
            "...          ...                                                ...   \n",
            "5388      E08016  The EU should integrate the armed forces of it...   \n",
            "5389      E08017  Food whose production has been subsidized with...   \n",
            "5390      E08018  Food whose production has been subsidized with...   \n",
            "5391      E08019  Food whose production has been subsidized with...   \n",
            "5392      E08020  The EU should integrate the armed forces of it...   \n",
            "\n",
            "      Self-direction: thought  Self-direction: action  Stimulation  Hedonism  \\\n",
            "0                           0                       0            0         0   \n",
            "1                           0                       0            0         0   \n",
            "2                           0                       0            0         0   \n",
            "3                           0                       0            0         0   \n",
            "4                           0                       0            0         0   \n",
            "...                       ...                     ...          ...       ...   \n",
            "5388                        0                       0            0         0   \n",
            "5389                        0                       0            0         0   \n",
            "5390                        0                       0            0         0   \n",
            "5391                        0                       0            0         0   \n",
            "5392                        0                       1            0         0   \n",
            "\n",
            "      Achievement  Power: dominance  Power: resources  Face  ...  \\\n",
            "0               0                 0                 0     0  ...   \n",
            "1               0                 0                 0     0  ...   \n",
            "2               0                 1                 0     0  ...   \n",
            "3               0                 0                 0     0  ...   \n",
            "4               0                 0                 0     0  ...   \n",
            "...           ...               ...               ...   ...  ...   \n",
            "5388            1                 1                 0     0  ...   \n",
            "5389            0                 0                 0     0  ...   \n",
            "5390            0                 0                 0     0  ...   \n",
            "5391            0                 0                 0     0  ...   \n",
            "5392            0                 1                 0     0  ...   \n",
            "\n",
            "      Conformity: rules  Conformity: interpersonal  Humility  \\\n",
            "0                     0                          0         0   \n",
            "1                     0                          0         0   \n",
            "2                     0                          0         0   \n",
            "3                     1                          0         0   \n",
            "4                     0                          0         0   \n",
            "...                 ...                        ...       ...   \n",
            "5388                  0                          0         0   \n",
            "5389                  1                          0         0   \n",
            "5390                  0                          0         0   \n",
            "5391                  1                          0         0   \n",
            "5392                  0                          0         0   \n",
            "\n",
            "      Benevolence: caring  Benevolence: dependability  Universalism: concern  \\\n",
            "0                       0                           0                      0   \n",
            "1                       0                           0                      0   \n",
            "2                       0                           0                      0   \n",
            "3                       0                           0                      1   \n",
            "4                       1                           0                      1   \n",
            "...                   ...                         ...                    ...   \n",
            "5388                    0                           1                      0   \n",
            "5389                    0                           1                      1   \n",
            "5390                    0                           1                      0   \n",
            "5391                    0                           1                      1   \n",
            "5392                    0                           1                      0   \n",
            "\n",
            "      Universalism: nature  Universalism: tolerance  \\\n",
            "0                        0                        0   \n",
            "1                        0                        0   \n",
            "2                        0                        0   \n",
            "3                        0                        0   \n",
            "4                        0                        0   \n",
            "...                    ...                      ...   \n",
            "5388                     0                        0   \n",
            "5389                     0                        0   \n",
            "5390                     1                        0   \n",
            "5391                     0                        0   \n",
            "5392                     0                        0   \n",
            "\n",
            "      Universalism: objectivity  \\\n",
            "0                             0   \n",
            "1                             0   \n",
            "2                             0   \n",
            "3                             0   \n",
            "4                             0   \n",
            "...                         ...   \n",
            "5388                          0   \n",
            "5389                          1   \n",
            "5390                          0   \n",
            "5391                          1   \n",
            "5392                          0   \n",
            "\n",
            "                                                 labels  \n",
            "0     (0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
            "1     (0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
            "2     (0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
            "3     (0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, ...  \n",
            "4     (0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...  \n",
            "...                                                 ...  \n",
            "5388  (0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
            "5389  (0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...  \n",
            "5390  (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
            "5391  (0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, ...  \n",
            "5392  (0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
            "\n",
            "[5393 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have implemented the following functions to determine the optimal threshold after training and assessing the model. This is necessary because the model's output consists of a series of probabilities, and these probabilities need to be transformed into binary values (0s and 1s) using a threshold."
      ],
      "metadata": {
        "id": "Em5c0ibs92X3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtaining the best optimal threshold\n",
        "def get_threshold(labels, model_output):\n",
        "  results = {}\n",
        "  labels_compressed = labels.drop(\"Argument ID\", axis=1)\n",
        "\n",
        "  df_prediction = labels_compressed.copy()\n",
        "  for tr in np.arange(0.1, 0.9, 0.05):\n",
        "      tr = round(tr, 2)\n",
        "      for i, label in enumerate(label_cols):\n",
        "          prediction = np.where(model_output[:,i] >= tr, 1, 0)\n",
        "          df_prediction[label] = prediction\n",
        "\n",
        "      y_pred = df_prediction.values.tolist()\n",
        "      y_test = labels_compressed.values.tolist()\n",
        "      f1 = f1_score(y_test, y_pred, average = \"macro\", zero_division = 1)\n",
        "      results[tr] = f1\n",
        "\n",
        "  for k,v in results.items():\n",
        "      print(\"THRESHOLD: {:.2f} \".format(k), \"F1 score: {:.3f}\".format(v))\n",
        "\n",
        "  THRESHOLD = max(results, key = results.get)\n",
        "\n",
        "  print(\"\\nBest threshold obtained:\", THRESHOLD , \"having F1 score of: {:.2f}\".format(max(results.values())))\n",
        "\n",
        "  return THRESHOLD"
      ],
      "metadata": {
        "id": "M7uCt-tL435f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the function below, we can get a report of the classification scores on various classes."
      ],
      "metadata": {
        "id": "-zz7Q6qV_ct3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtaining the final report of our scores\n",
        "def get_report(labels, model_output, THRESHOLD):\n",
        "  print(labels)\n",
        "  print(model_output)\n",
        "  print(THRESHOLD)\n",
        "  df_prediction = labels.copy()\n",
        "\n",
        "  for i, label in enumerate(label_cols):\n",
        "    prediction = np.where(model_output[:,i] >= THRESHOLD, 1, 0)\n",
        "    df_prediction[label] = prediction\n",
        "\n",
        "  y_pred = df_prediction.values.tolist()\n",
        "  y_test = labels.values.tolist()\n",
        "\n",
        "  print(classification_report(y_test,y_pred, target_names = label_cols))"
      ],
      "metadata": {
        "id": "1TWN0K0w5da_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the Model\n",
        "\n",
        "\n",
        "In this section, we introduce our BERT model and initiate the fine-tuning process by exploring various parameters. To facilitate this experimentation, we make use of the Sweep library, which enables us to systematically evaluate different model configurations.\n",
        "\n",
        "We work with two versions of the BERT model, namely \"bert-base-cased\" and \"bert-large-cased.\" However, owing to constraints with our CUDA resources, we begin by fine-tuning \"bert-base-cased\" using hyperparameter tuning to identify the optimal hyperparameters. Once we've determined the best hyperparameters for \"bert-base-cased,\" we proceed to train both the \"bert-base-cased\" and \"bert-large-cased\" models. This approach allows us to make a fair and meaningful comparison of their performance on our datasets."
      ],
      "metadata": {
        "id": "7K5ZVKpEeFmt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining Hyperparameter\n",
        "\n",
        "\n",
        "We attempted to conduct experiments by varying the parameters related to the number of training epochs and the batch size."
      ],
      "metadata": {
        "id": "-DcNJM_9KSjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparmaters we want to fine-tune\n",
        "sweep_config = {\n",
        "    \"method\": \"grid\",  # grid, random\n",
        "    \"parameters\": {\n",
        "        \"num_train_epochs\": {\"values\": [3, 5, 10]},\n",
        "        \"train_batch_size\": {\"values\": [16, 32]}\n",
        "    },\n",
        "}"
      ],
      "metadata": {
        "id": "OGLLHlc3W_B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a sweep in W&B\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"Human Value Detection\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "pqwv4SWLXTTR",
        "outputId": "557c83f4-14ec-4be2-a0ef-c8461ee99243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: gr6rewmr\n",
            "Sweep URL: https://wandb.ai/human-value-detection/Human%20Value%20Detection/sweeps/gr6rewmr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)"
      ],
      "metadata": {
        "id": "rV5T6eF4XTWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our fixed arguments for the simple transformers model\n",
        "args = {\n",
        "      'manual_seed': 42,\n",
        "      'max_seq_length': 100,\n",
        "      'overwrite_output_dir': True,\n",
        "      'gradient_accumulation_steps': 8,\n",
        "      \"lr\": 2e-4,\n",
        "      \"optimizer\": 'AdamW'\n",
        "      }"
      ],
      "metadata": {
        "id": "ldCIZBusVX9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT Base\n",
        "This section contains the training phase for our BERT base model:"
      ],
      "metadata": {
        "id": "LvLbxUdaNVXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    # Initialize a new wandb run\n",
        "    wandb.init()\n",
        "\n",
        "    # Create a TransformerModel\n",
        "    model = MultiLabelClassificationModel(\n",
        "        'bert',\n",
        "        'bert-base-cased',\n",
        "        use_cuda=True,\n",
        "        args=args,\n",
        "        sweep_config=wandb.config,\n",
        "        num_labels=20\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    model.train_model(merged_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    model.eval_model(merged_val)\n",
        "\n",
        "    # Sync wandb\n",
        "    wandb.join()\n"
      ],
      "metadata": {
        "id": "XxUzxpBRXcRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, train, count=6)"
      ],
      "metadata": {
        "id": "9WRPg6JrXfMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the W&B API\n",
        "api = wandb.Api()\n",
        "\n",
        "# Replace 'your_project_name' with your actual project name\n",
        "project = api.project('Human Value Detection')\n",
        "\n",
        "project"
      ],
      "metadata": {
        "id": "7PxRpBThnWw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the sweep\n",
        "sweep = api.sweep(f\"{project.name}/{sweep_id}\")\n",
        "\n",
        "# Retrieve the best run\n",
        "best_run = sweep.best_run()\n",
        "\n",
        "# Get the best run's parameters and results\n",
        "best_params = best_run.config\n",
        "best_results = best_run.summary"
      ],
      "metadata": {
        "id": "ut206MXvo2AJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11d9791c-f350-4d88-8fd4-3da7082de2d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m No order specified and couldn't find metric in sweep config, returning most recent run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Results:\", best_results)"
      ],
      "metadata": {
        "id": "8IsW7k9EpqbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ce8bd93-7faf-49fe-8eaf-998deced3819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'num_train_epochs': 10, 'train_batch_size': 32}\n",
            "Best Results: {'_runtime': 322.14150643348694, '_timestamp': 1693808617.0067475, 'global_step': 200, 'Training loss': 0.3118610978126526, 'lr': 2.0304568527918785e-06, '_step': 3, '_wandb': {'runtime': 341}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Defining the model using the best parameters obtained\n",
        " model_bert_base = MultiLabelClassificationModel(\n",
        "        'bert',\n",
        "        'bert-base-cased',\n",
        "        use_cuda=True,\n",
        "        args={\n",
        "              'num_train_epochs': best_params['num_train_epochs'],\n",
        "              'train_batch_size': best_params['train_batch_size'],\n",
        "              'manual_seed': 42,\n",
        "              'max_seq_length': 100,\n",
        "              'overwrite_output_dir': True,\n",
        "              'gradient_accumulation_steps': 8,\n",
        "              \"lr\": 2e-4,\n",
        "              \"optimizer\": 'AdamW'\n",
        "            },\n",
        "        num_labels=20\n",
        ")"
      ],
      "metadata": {
        "id": "xQEPJQJ8pxFd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fd3c297-107e-4509-e477-1bd981e61a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# layers of our bert base model\n",
        "model_bert_base.model"
      ],
      "metadata": {
        "id": "UtxiH7OqrQB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e09fce8e-172e-47fd-bf9e-05001f216833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMultiLabelSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=20, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model\n",
        "model_bert_base.train_model(merged_train, eval_df=merged_val)"
      ],
      "metadata": {
        "id": "8X9lmg8urSsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bert Large\n",
        "\n",
        "This section encompasses the training phase for our BERT large model."
      ],
      "metadata": {
        "id": "0wbn5Y2PBHMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining our bert large model with the hyperparameters we got from bert base\n",
        "model_bert_large = MultiLabelClassificationModel(\n",
        "        'bert',\n",
        "        'bert-large-cased',\n",
        "        use_cuda=True,\n",
        "        args={\n",
        "              'num_train_epochs': best_params['num_train_epochs'],\n",
        "              'train_batch_size': best_params['train_batch_size'],\n",
        "              'manual_seed': 42,\n",
        "              'max_seq_length': 100,\n",
        "              'overwrite_output_dir': True,\n",
        "              'gradient_accumulation_steps': 8,\n",
        "              \"lr\": 2e-4,\n",
        "              \"optimizer\": 'AdamW'\n",
        "            },\n",
        "        num_labels=20\n",
        ")"
      ],
      "metadata": {
        "id": "5Ybq_d-fBJqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Layers of our bert large model\n",
        "model_bert_large.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6di-AfIC1Aa",
        "outputId": "805ea20a-cc63-4736-e07f-4dde71f1c21f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMultiLabelSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-23): 24 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=20, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training our bert large model\n",
        "model_bert_large.train_model(merged_train, eval_df=merged_val)"
      ],
      "metadata": {
        "id": "x2bYwREZDGbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of the models\n",
        "\n",
        "\n",
        "In this section, we assess the performance of the BERT base and BERT large models on both the validation and test sets. We gauge their performance using the F1 score as the primary metric for evaluation."
      ],
      "metadata": {
        "id": "_0Oe2OLe6hR9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation of bert-base-cased\n",
        "In here, we evaluate the BERT base model on both the validation and test datasets."
      ],
      "metadata": {
        "id": "i28OwB0ZmfLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation on validation set**"
      ],
      "metadata": {
        "id": "-IHdame-BS2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_bert_base, model_outputs_bert_base, wrong_predictions_bert_base = model_bert_base.eval_model(merged_val)\n",
        "print(\"Results of bert base on validtion set:\\n\", result_bert_base)"
      ],
      "metadata": {
        "id": "AgwzIKW3uZVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_base_threshold = get_threshold(val_labels, model_outputs_bert_base)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S64ls6P6jJY",
        "outputId": "7c53c9be-cd95-46f2-8dca-282b1d6b5c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THRESHOLD: 0.10  F1 score: 0.344\n",
            "THRESHOLD: 0.15  F1 score: 0.363\n",
            "THRESHOLD: 0.20  F1 score: 0.348\n",
            "THRESHOLD: 0.25  F1 score: 0.327\n",
            "THRESHOLD: 0.30  F1 score: 0.304\n",
            "THRESHOLD: 0.35  F1 score: 0.279\n",
            "THRESHOLD: 0.40  F1 score: 0.245\n",
            "THRESHOLD: 0.45  F1 score: 0.209\n",
            "THRESHOLD: 0.50  F1 score: 0.176\n",
            "THRESHOLD: 0.55  F1 score: 0.150\n",
            "THRESHOLD: 0.60  F1 score: 0.124\n",
            "THRESHOLD: 0.65  F1 score: 0.099\n",
            "THRESHOLD: 0.70  F1 score: 0.070\n",
            "THRESHOLD: 0.75  F1 score: 0.043\n",
            "THRESHOLD: 0.80  F1 score: 0.016\n",
            "THRESHOLD: 0.85  F1 score: 0.003\n",
            "\n",
            "Best threshold obtained: 0.15 having F1 score of: 0.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_report(val_labels, model_outputs_bert_base, bert_base_threshold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaiOcCStBjSY",
        "outputId": "e4bf4766-2f8b-4f87-ce7b-f57ba088f04f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "   Self-direction: thought       0.30      0.68      0.42       251\n",
            "    Self-direction: action       0.33      0.81      0.47       496\n",
            "               Stimulation       0.30      0.12      0.17       138\n",
            "                  Hedonism       0.64      0.07      0.12       103\n",
            "               Achievement       0.39      0.91      0.55       575\n",
            "          Power: dominance       0.23      0.45      0.30       164\n",
            "          Power: resources       0.23      0.86      0.37       132\n",
            "                      Face       0.21      0.18      0.19       130\n",
            "        Security: personal       0.43      0.99      0.59       759\n",
            "        Security: societal       0.35      0.91      0.50       488\n",
            "                 Tradition       0.36      0.41      0.38       172\n",
            "         Conformity: rules       0.32      0.85      0.46       455\n",
            " Conformity: interpersonal       0.00      0.00      0.00        60\n",
            "                  Humility       0.20      0.11      0.14       127\n",
            "       Benevolence: caring       0.34      1.00      0.51       633\n",
            "Benevolence: dependability       0.16      0.67      0.25       268\n",
            "     Universalism: concern       0.39      0.99      0.56       687\n",
            "      Universalism: nature       0.52      0.68      0.59       127\n",
            "   Universalism: tolerance       0.22      0.40      0.28       223\n",
            " Universalism: objectivity       0.24      0.87      0.38       371\n",
            "\n",
            "                 micro avg       0.33      0.79      0.46      6359\n",
            "                 macro avg       0.31      0.60      0.36      6359\n",
            "              weighted avg       0.33      0.79      0.45      6359\n",
            "               samples avg       0.33      0.81      0.45      6359\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation on test set**\n"
      ],
      "metadata": {
        "id": "14gOgk8_URoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_bert_base_test, model_outputs_bert_base_test, wrong_predictions_bert_base_test = model_bert_base.eval_model(merged_test)\n",
        "print(\"Results of bert base on validtion set:\\n\", result_bert_base_test)"
      ],
      "metadata": {
        "id": "f1YPpgBtVVQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_base_threshold_test = get_threshold(test_labels, model_outputs_bert_base_test)"
      ],
      "metadata": {
        "id": "oA7aq5C3VdCV",
        "outputId": "69026b54-1370-4224-943b-d696b1b197c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THRESHOLD: 0.10  F1 score: 0.309\n",
            "THRESHOLD: 0.15  F1 score: 0.340\n",
            "THRESHOLD: 0.20  F1 score: 0.330\n",
            "THRESHOLD: 0.25  F1 score: 0.308\n",
            "THRESHOLD: 0.30  F1 score: 0.284\n",
            "THRESHOLD: 0.35  F1 score: 0.261\n",
            "THRESHOLD: 0.40  F1 score: 0.235\n",
            "THRESHOLD: 0.45  F1 score: 0.208\n",
            "THRESHOLD: 0.50  F1 score: 0.176\n",
            "THRESHOLD: 0.55  F1 score: 0.155\n",
            "THRESHOLD: 0.60  F1 score: 0.133\n",
            "THRESHOLD: 0.65  F1 score: 0.112\n",
            "THRESHOLD: 0.70  F1 score: 0.088\n",
            "THRESHOLD: 0.75  F1 score: 0.057\n",
            "THRESHOLD: 0.80  F1 score: 0.026\n",
            "THRESHOLD: 0.85  F1 score: 0.004\n",
            "\n",
            "Best threshold obtained: 0.15 having F1 score of: 0.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_report(test_labels, model_outputs_bert_base_test, bert_base_threshold_test)"
      ],
      "metadata": {
        "id": "S7-jge1hV2nl",
        "outputId": "b1c8dcb2-0371-4a31-ad23-7a67fa1b48ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "   Self-direction: thought       0.22      0.62      0.33       143\n",
            "    Self-direction: action       0.34      0.87      0.49       391\n",
            "               Stimulation       0.19      0.08      0.11        77\n",
            "                  Hedonism       0.17      0.08      0.11        26\n",
            "               Achievement       0.38      0.80      0.51       412\n",
            "          Power: dominance       0.18      0.52      0.27       108\n",
            "          Power: resources       0.27      0.77      0.40       105\n",
            "                      Face       0.17      0.08      0.11        96\n",
            "        Security: personal       0.37      1.00      0.54       537\n",
            "        Security: societal       0.31      0.92      0.47       397\n",
            "                 Tradition       0.29      0.64      0.40       168\n",
            "         Conformity: rules       0.26      0.94      0.41       287\n",
            " Conformity: interpersonal       0.08      0.02      0.03        53\n",
            "                  Humility       0.05      0.09      0.07        74\n",
            "       Benevolence: caring       0.21      1.00      0.35       336\n",
            "Benevolence: dependability       0.12      0.59      0.20       163\n",
            "     Universalism: concern       0.41      0.98      0.58       588\n",
            "      Universalism: nature       0.57      0.65      0.61       144\n",
            "   Universalism: tolerance       0.23      0.61      0.33       195\n",
            " Universalism: objectivity       0.36      0.66      0.47       471\n",
            "\n",
            "                 micro avg       0.30      0.78      0.43      4771\n",
            "                 macro avg       0.26      0.60      0.34      4771\n",
            "              weighted avg       0.31      0.78      0.44      4771\n",
            "               samples avg       0.31      0.81      0.42      4771\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation of bert-large-cased\n",
        "This section involves the evaluation of the BERT large model on both the validation and test datasets."
      ],
      "metadata": {
        "id": "tuTz6W6kWQ8p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation on validation set**"
      ],
      "metadata": {
        "id": "H08yz78DWUx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_bert_large, model_outputs_bert_large, wrong_predictions_bert_large = model_bert_large.eval_model(merged_val)\n",
        "print(\"Results of bert base on validtion set:\\n\", result_bert_large)"
      ],
      "metadata": {
        "id": "lQox1dByWbfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_large_threshold = get_threshold(val_labels, model_outputs_bert_large)"
      ],
      "metadata": {
        "id": "mK-RNdI2Wdlp",
        "outputId": "e597a563-7e82-44aa-b488-9779129215b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THRESHOLD: 0.10  F1 score: 0.398\n",
            "THRESHOLD: 0.15  F1 score: 0.420\n",
            "THRESHOLD: 0.20  F1 score: 0.414\n",
            "THRESHOLD: 0.25  F1 score: 0.398\n",
            "THRESHOLD: 0.30  F1 score: 0.379\n",
            "THRESHOLD: 0.35  F1 score: 0.356\n",
            "THRESHOLD: 0.40  F1 score: 0.337\n",
            "THRESHOLD: 0.45  F1 score: 0.318\n",
            "THRESHOLD: 0.50  F1 score: 0.296\n",
            "THRESHOLD: 0.55  F1 score: 0.268\n",
            "THRESHOLD: 0.60  F1 score: 0.248\n",
            "THRESHOLD: 0.65  F1 score: 0.219\n",
            "THRESHOLD: 0.70  F1 score: 0.192\n",
            "THRESHOLD: 0.75  F1 score: 0.161\n",
            "THRESHOLD: 0.80  F1 score: 0.126\n",
            "THRESHOLD: 0.85  F1 score: 0.088\n",
            "\n",
            "Best threshold obtained: 0.15 having F1 score of: 0.42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_report(val_labels, model_outputs_bert_large, bert_large_threshold)"
      ],
      "metadata": {
        "id": "NJ_EqCyhWfZy",
        "outputId": "7c9a4cf7-d163-4559-9e43-8de590eb035f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "   Self-direction: thought       0.32      0.75      0.45       251\n",
            "    Self-direction: action       0.43      0.76      0.54       496\n",
            "               Stimulation       0.31      0.20      0.24       138\n",
            "                  Hedonism       0.38      0.35      0.36       103\n",
            "               Achievement       0.47      0.86      0.61       575\n",
            "          Power: dominance       0.23      0.48      0.31       164\n",
            "          Power: resources       0.31      0.85      0.46       132\n",
            "                      Face       0.19      0.15      0.17       130\n",
            "        Security: personal       0.52      0.95      0.68       759\n",
            "        Security: societal       0.40      0.86      0.54       488\n",
            "                 Tradition       0.36      0.47      0.40       172\n",
            "         Conformity: rules       0.39      0.80      0.53       455\n",
            " Conformity: interpersonal       0.20      0.08      0.12        60\n",
            "                  Humility       0.20      0.23      0.21       127\n",
            "       Benevolence: caring       0.38      0.94      0.54       633\n",
            "Benevolence: dependability       0.19      0.69      0.29       268\n",
            "     Universalism: concern       0.45      0.95      0.61       687\n",
            "      Universalism: nature       0.65      0.71      0.68       127\n",
            "   Universalism: tolerance       0.20      0.27      0.23       223\n",
            " Universalism: objectivity       0.28      0.75      0.41       371\n",
            "\n",
            "                 micro avg       0.38      0.76      0.51      6359\n",
            "                 macro avg       0.34      0.61      0.42      6359\n",
            "              weighted avg       0.39      0.76      0.50      6359\n",
            "               samples avg       0.39      0.79      0.50      6359\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation on test set**"
      ],
      "metadata": {
        "id": "Az-KIUUsYAUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_bert_large_test, model_outputs_bert_large_test, wrong_predictions_bert_large_test = model_bert_large.eval_model(merged_test)\n",
        "print(\"Results of bert base on validtion set:\\n\", result_bert_large_test)"
      ],
      "metadata": {
        "id": "JG58iBriYQFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_large_threshold_test = get_threshold(test_labels, model_outputs_bert_large_test)"
      ],
      "metadata": {
        "id": "daotfTNSYZ8Z",
        "outputId": "ba937159-21cd-492d-a36f-49195497a232",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THRESHOLD: 0.10  F1 score: 0.372\n",
            "THRESHOLD: 0.15  F1 score: 0.402\n",
            "THRESHOLD: 0.20  F1 score: 0.410\n",
            "THRESHOLD: 0.25  F1 score: 0.408\n",
            "THRESHOLD: 0.30  F1 score: 0.391\n",
            "THRESHOLD: 0.35  F1 score: 0.370\n",
            "THRESHOLD: 0.40  F1 score: 0.351\n",
            "THRESHOLD: 0.45  F1 score: 0.328\n",
            "THRESHOLD: 0.50  F1 score: 0.306\n",
            "THRESHOLD: 0.55  F1 score: 0.287\n",
            "THRESHOLD: 0.60  F1 score: 0.265\n",
            "THRESHOLD: 0.65  F1 score: 0.246\n",
            "THRESHOLD: 0.70  F1 score: 0.221\n",
            "THRESHOLD: 0.75  F1 score: 0.184\n",
            "THRESHOLD: 0.80  F1 score: 0.143\n",
            "THRESHOLD: 0.85  F1 score: 0.101\n",
            "\n",
            "Best threshold obtained: 0.2 having F1 score of: 0.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_report(test_labels, model_outputs_bert_large_test, bert_large_threshold_test)"
      ],
      "metadata": {
        "id": "7z_6rtDXYlmj",
        "outputId": "5d540174-1de6-4325-a4a4-4110871cfbc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "   Self-direction: thought       0.34      0.65      0.44       143\n",
            "    Self-direction: action       0.51      0.71      0.59       391\n",
            "               Stimulation       0.33      0.04      0.07        77\n",
            "                  Hedonism       0.31      0.19      0.24        26\n",
            "               Achievement       0.52      0.67      0.58       412\n",
            "          Power: dominance       0.26      0.38      0.31       108\n",
            "          Power: resources       0.39      0.69      0.50       105\n",
            "                      Face       0.22      0.04      0.07        96\n",
            "        Security: personal       0.52      0.92      0.66       537\n",
            "        Security: societal       0.38      0.87      0.53       397\n",
            "                 Tradition       0.42      0.65      0.51       168\n",
            "         Conformity: rules       0.34      0.82      0.48       287\n",
            " Conformity: interpersonal       0.31      0.09      0.14        53\n",
            "                  Humility       0.10      0.12      0.11        74\n",
            "       Benevolence: caring       0.31      0.78      0.44       336\n",
            "Benevolence: dependability       0.25      0.42      0.31       163\n",
            "     Universalism: concern       0.50      0.94      0.65       588\n",
            "      Universalism: nature       0.76      0.73      0.74       144\n",
            "   Universalism: tolerance       0.31      0.42      0.36       195\n",
            " Universalism: objectivity       0.50      0.41      0.45       471\n",
            "\n",
            "                 micro avg       0.42      0.68      0.52      4771\n",
            "                 macro avg       0.38      0.53      0.41      4771\n",
            "              weighted avg       0.43      0.68      0.51      4771\n",
            "               samples avg       0.44      0.72      0.52      4771\n",
            "\n"
          ]
        }
      ]
    }
  ]
}